{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset from kaggle as the harvard link did not work"
      ],
      "metadata": {
        "id": "psouWh6bvJ7k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgGmoBvlqnP2",
        "outputId": "9ac98113-7b61-4959-91d1-93eb35551fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Dataset URL: https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading skin-cancer-mnist-ham10000.zip to /content\n",
            "100% 5.20G/5.20G [02:50<00:00, 35.5MB/s]\n",
            "100% 5.20G/5.20G [02:50<00:00, 32.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download HAM10000 dataset\n",
        "!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip the dataset"
      ],
      "metadata": {
        "id": "MXidk-0DvOhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "with zipfile.ZipFile(\"skin-cancer-mnist-ham10000.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"HAM10000\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NBa7n8hbrzX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Columns:**\n",
        "\n",
        "\n",
        "1. lesion_id: Identifier for the lesion which may be shared by multiple images of the same lesion\n",
        "2. image_id: Unique identifier for each image\n",
        "3. dx: Diagnosis label for the lesion:\n",
        "  - nv: Melanocytic nevi\n",
        "  - mel: Melanoma\n",
        "  - bkl: Benign keratosis\n",
        "  - ...\n",
        "4. dx_type: Method to obtain the diagnosis:\n",
        "  - histo: Analyzing a biopsy under microscope\n",
        "  - follow_up: Diagnosis was determined through clinical follow-up over time\n",
        "5. age: Age of the participant\n",
        "6. sex: Sex of the participant\n",
        "7. localization: Body site where the lesion was found\n",
        "\n"
      ],
      "metadata": {
        "id": "7j0LBzYzsVwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_path = \"HAM10000/HAM10000_metadata.csv\"\n",
        "metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "print(metadata.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsV5p-xZsKVL",
        "outputId": "1ce9098a-4763-410a-c0c2-a898a1ec4a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     lesion_id      image_id   dx dx_type   age   sex localization\n",
            "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
            "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
            "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
            "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
            "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check data for correctness"
      ],
      "metadata": {
        "id": "G2ad3yAMvUrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "Ydwxr00xvS3M",
        "outputId": "d6ba01fe-ad13-4f4f-bae3-a59feec55132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lesion_id        0\n",
              "image_id         0\n",
              "dx               0\n",
              "dx_type          0\n",
              "age             57\n",
              "sex              0\n",
              "localization     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>lesion_id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dx</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dx_type</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>localization</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we are training a model which should determine the illness based on the image, rows with age column == null do not have to be dropped"
      ],
      "metadata": {
        "id": "YKNCDWuzvqNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd HAM10000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPmf-lM_xR_V",
        "outputId": "1c5d28a5-3603-47bc-b968-427eb1eb45f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HAM10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "target_dir = \"HAM10000_images_combined\"\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "for folder in [\"HAM10000_images_part_1\", \"HAM10000_images_part_2\"]:\n",
        "    for file in os.listdir(folder):\n",
        "        shutil.copy(os.path.join(folder, file), target_dir)"
      ],
      "metadata": {
        "id": "bDlkgpHCxMIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. HAM10000_images_part_1/ and HAM10000_images_part_2/: These are the directories being removed.\n",
        "2. ham10000_images_part_1/ and ham10000_images_part_2/: These are the directories being removed."
      ],
      "metadata": {
        "id": "iKXDUmwR0J1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r HAM10000_images_part_1/\n",
        "!rm -r HAM10000_images_part_2/\n",
        "!rm -r ham10000_images_part_1/\n",
        "!rm -r ham10000_images_part_2/"
      ],
      "metadata": {
        "id": "YT1QXBy8yhRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if there are entries without images"
      ],
      "metadata": {
        "id": "Bys1-4qwy-ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "image_dir = \"HAM10000_images_combined/\"\n",
        "\n",
        "image_files = set(os.listdir(image_dir))\n",
        "\n",
        "metadata['image_id'] = metadata['image_id'] + \".jpg\"\n",
        "\n",
        "missing_files = metadata.loc[~metadata['image_id'].isin(image_files), 'image_id']\n",
        "\n",
        "if len(missing_files) > 0:\n",
        "    print(f\"Missing files for {len(missing_files)} image IDs:\")\n",
        "    print(missing_files.tolist())\n",
        "else:\n",
        "    print(\"All image files are present.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTXXHF0Bvp6c",
        "outputId": "49f4e685-a42b-446f-f0a5-a97855aaca33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All image files are present.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the file path for each image to the metadata"
      ],
      "metadata": {
        "id": "9_RYrREj0jIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata['image_path'] = metadata['image_id'].apply(lambda x: os.path.join(\"HAM10000_images_combined\", f\"{x}\"))"
      ],
      "metadata": {
        "id": "J7zeT6Go0i3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(metadata.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlF45-Jw0ser",
        "outputId": "6937725f-45c2-47c0-bb3b-3b1c211efa20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     lesion_id          image_id   dx dx_type   age   sex localization  \\\n",
            "0  HAM_0000118  ISIC_0027419.jpg  bkl   histo  80.0  male        scalp   \n",
            "1  HAM_0000118  ISIC_0025030.jpg  bkl   histo  80.0  male        scalp   \n",
            "2  HAM_0002730  ISIC_0026769.jpg  bkl   histo  80.0  male        scalp   \n",
            "3  HAM_0002730  ISIC_0025661.jpg  bkl   histo  80.0  male        scalp   \n",
            "4  HAM_0001466  ISIC_0031633.jpg  bkl   histo  75.0  male          ear   \n",
            "\n",
            "                                  image_path  \n",
            "0  HAM10000_images_combined/ISIC_0027419.jpg  \n",
            "1  HAM10000_images_combined/ISIC_0025030.jpg  \n",
            "2  HAM10000_images_combined/ISIC_0026769.jpg  \n",
            "3  HAM10000_images_combined/ISIC_0025661.jpg  \n",
            "4  HAM10000_images_combined/ISIC_0031633.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balance the label set"
      ],
      "metadata": {
        "id": "hE12ehqh1jBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(metadata['dx']),\n",
        "    y=metadata['dx']\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))"
      ],
      "metadata": {
        "id": "iuNcqv551yq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(class_weights_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsFhJk9D1_Ym",
        "outputId": "acb988f4-b533-4646-e2af-a3b38418e239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 4.375273044997815, 1: 2.78349082823791, 2: 1.301832835044846, 3: 12.440993788819876, 4: 1.2854575792581184, 5: 0.21338020666879728, 6: 10.075452716297788}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate train / test split"
      ],
      "metadata": {
        "id": "44QkK1dC4Pg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(metadata, test_size=0.2, stratify=metadata['dx'], random_state=42)"
      ],
      "metadata": {
        "id": "mD4f4Qaj4RTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boilerplate for data loading"
      ],
      "metadata": {
        "id": "GqcgWVVc4qOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(train_df.head())\n",
        "\n",
        "img_size = 128\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='image_path',\n",
        "    y_col='dx',\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    x_col='image_path',\n",
        "    y_col='dx',\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg7FMoD04rwn",
        "outputId": "42b62584-3014-4cb9-a991-54065728a241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        lesion_id          image_id     dx    dx_type   age     sex  \\\n",
            "8050  HAM_0005972  ISIC_0033319.jpg     nv      histo  35.0  female   \n",
            "4898  HAM_0004902  ISIC_0030823.jpg     nv  follow_up  40.0    male   \n",
            "9695  HAM_0005282  ISIC_0028730.jpg  akiec      histo  65.0    male   \n",
            "4090  HAM_0000475  ISIC_0027299.jpg     nv  follow_up  40.0    male   \n",
            "8625  HAM_0000949  ISIC_0032444.jpg     nv      histo  65.0    male   \n",
            "\n",
            "         localization                                 image_path  \n",
            "8050  lower extremity  HAM10000_images_combined/ISIC_0033319.jpg  \n",
            "4898            trunk  HAM10000_images_combined/ISIC_0030823.jpg  \n",
            "9695  lower extremity  HAM10000_images_combined/ISIC_0028730.jpg  \n",
            "4090  lower extremity  HAM10000_images_combined/ISIC_0027299.jpg  \n",
            "8625             back  HAM10000_images_combined/ISIC_0032444.jpg  \n",
            "Found 8012 validated image filenames belonging to 7 classes.\n",
            "Found 2003 validated image filenames belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "kWDY-N6a6IZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "num_classes = train_df['dx'].nunique()\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10,\n",
        "    class_weight=class_weights_dict\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0nbqTNZ6Huu",
        "outputId": "538eb3a5-4dd6-4d93-f0f6-06385e00926c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 1s/step - accuracy: 0.2761 - loss: 23.1052 - val_accuracy: 0.0295 - val_loss: 2.3635\n",
            "Epoch 2/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 1s/step - accuracy: 0.2294 - loss: 6.3015 - val_accuracy: 0.0704 - val_loss: 1.9699\n",
            "Epoch 3/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 1s/step - accuracy: 0.1478 - loss: 3.0821 - val_accuracy: 0.0744 - val_loss: 2.0031\n",
            "Epoch 4/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 1s/step - accuracy: 0.1510 - loss: 2.5484 - val_accuracy: 0.2886 - val_loss: 2.2320\n",
            "Epoch 5/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 1s/step - accuracy: 0.1526 - loss: 2.2719 - val_accuracy: 0.1288 - val_loss: 1.9459\n",
            "Epoch 6/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 1s/step - accuracy: 0.1328 - loss: 2.0747 - val_accuracy: 0.1393 - val_loss: 2.3207\n",
            "Epoch 7/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 2s/step - accuracy: 0.1063 - loss: 2.3017 - val_accuracy: 0.1932 - val_loss: 2.4728\n",
            "Epoch 8/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 1s/step - accuracy: 0.1295 - loss: 2.1090 - val_accuracy: 0.2821 - val_loss: 2.3332\n",
            "Epoch 9/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 1s/step - accuracy: 0.1153 - loss: 2.2077 - val_accuracy: 0.1912 - val_loss: 1.7497\n",
            "Epoch 10/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 1s/step - accuracy: 0.1000 - loss: 2.1127 - val_accuracy: 0.0934 - val_loss: 2.0470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Monte Carlo Dropout"
      ],
      "metadata": {
        "id": "RxEA0Wxi6VLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "mc_model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5, name='mc_dropout'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "mc_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "mc_model.set_weights(model.get_weights())\n",
        "\n",
        "@tf.function\n",
        "def monte_carlo_predictions(mc_model, x_batch, n_simulations=50):\n",
        "    preds = []\n",
        "    for _ in range(n_simulations):\n",
        "        preds.append(mc_model(x_batch, training=True))  # Force dropout during inference\n",
        "    preds = tf.stack(preds, axis=0)  # Shape: (n_simulations, batch_size, num_classes)\n",
        "    return tf.reduce_mean(preds, axis=0), tf.math.reduce_std(preds, axis=0)"
      ],
      "metadata": {
        "id": "pNVOrfqk6XB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the models"
      ],
      "metadata": {
        "id": "NMagHeETupaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"skin_lesion_model.keras\")\n",
        "\n",
        "mc_model.save(\"monte_carlo_model.keras\")"
      ],
      "metadata": {
        "id": "9IV-oW3Culxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test on Validation Data"
      ],
      "metadata": {
        "id": "UZ3ytTrq6eLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "test_image_path = val_df.iloc[0]['image_path']\n",
        "test_image_result = val_df.iloc[0]['dx']\n",
        "test_image = load_img(test_image_path, target_size=(img_size, img_size))\n",
        "test_image_array = img_to_array(test_image) / 255.0\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "\n",
        "mean_pred, uncertainty = monte_carlo_predictions(mc_model, test_image_array, n_simulations=50)\n",
        "\n",
        "predicted_class = np.argmax(mean_pred.numpy(), axis=-1)[0]\n",
        "print(\"Predicted class:\", val_df['dx'].unique()[predicted_class])\n",
        "print(\"Real class:\", test_image_result)\n",
        "print(\"Uncertainty:\", uncertainty.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wq82Xp86ch8",
        "outputId": "226f3a7e-92b0-4d11-c355-53759227f76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: nv\n",
            "Real class: nv\n",
            "Uncertainty: [[4.4703484e-08 4.4703484e-08 5.9604645e-08 8.9406967e-08 5.9604645e-08\n",
            "  2.9802322e-08 7.4505806e-08]]\n"
          ]
        }
      ]
    }
  ]
}